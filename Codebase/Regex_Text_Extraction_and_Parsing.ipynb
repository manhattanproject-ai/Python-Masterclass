{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regular Expression\n",
        "\n",
        "Imagine you have a big pile of documents, and you need to find all the phone numbers in them.  You could read every single word, but that would take forever! Instead, you can use a \"search pattern\" to find all the phone numbers quickly.\n",
        "\n",
        "That \"search pattern\" is what a regular expression (regex) is.\n",
        "\n",
        "Think of it like a super-powered search tool that understands patterns, not just exact words.\n",
        "\n",
        "Here's a simple analogy:\n",
        "\n",
        "* Normal search: If you search for \"cat,\" you'll only find the word \"cat.\"\n",
        "* Regex search: You can create a pattern that says, \"Find anything that looks like a phone number: three digits, then a hyphen, then three more digits, then another hyphen, and then four digits.\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qiygNpuPcJpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Extraction and Parsing"
      ],
      "metadata": {
        "id": "7r-79ylOt-wK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Extract product prices\n",
        "\n",
        "The regex pattern allows the function to extract both whole dollar amounts and amounts with cents from HTML content, providing flexibility in handling various price formats.\n",
        "\n",
        "Business Use Cases:\n",
        "\n",
        "* E-commerce Price Monitoring: Competitor price tracking, dynamic pricing adjustments, identifying pricing errors.\n",
        "* Retail Analytics: Analyzing product pricing trends across various online stores, understanding consumer price sensitivity.\n",
        "* Financial Data Aggregation: Gathering stock prices, commodity prices, or real estate values from web pages.\n",
        "* Travel Industry: Extracting hotel or flight prices from travel websites."
      ],
      "metadata": {
        "id": "hpWYAAdQvYVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_product_price(html_content):\n",
        "    \"\"\"\n",
        "    Extracts product prices from HTML content, including whole dollar amounts and amounts with cents.\n",
        "    \"\"\"\n",
        "    price_pattern = r\"\\$\\d+(?:\\.\\d{2})?\"  # Matches dollar amounts (e.g., $10, $10.99)\n",
        "    prices = re.findall(price_pattern, html_content)\n",
        "    return prices"
      ],
      "metadata": {
        "id": "HJvnGkoybIh1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed Example:\n",
        "html_text = \"\"\"\n",
        "<p>Product A: $10</p>\n",
        "<p>Product B: $19.99</p>\n",
        "<p>Product C: $100</p>\n",
        "<p>Product D: $5.50</p>\n",
        "<p>Product E: $0.99</p>\n",
        "<p>Product F: $12345</p>\n",
        "<p>Product G: $123.45</p>\n",
        "<p>Product H: $12.34</p>\n",
        "<p>Product I: This is not a price: $abc</p>\n",
        "<p>Product J: This is not a price: 10.99$</p>\n",
        "\"\"\"\n",
        "\n",
        "extracted_prices = extract_product_price(html_text)\n",
        "print(\"Extracted Prices:\", extracted_prices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiME70hVetSf",
        "outputId": "b735867a-f361-4dbc-c8b6-233c3ffa3952"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Prices: ['$10', '$19.99', '$100', '$5.50', '$0.99', '$12345', '$123.45', '$12.34']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Extract Contact Details\n",
        "\n",
        "Example Breakdown:\n",
        "\n",
        "* The html_text string contains various email addresses and phone numbers, including valid and invalid examples.\n",
        "* The extract_contact_details function uses the regex patterns to find and extract the valid email addresses and phone numbers.\n",
        "* The contact_details dictionary will contain the extracted information.\n",
        "* Invalid email addresses and phone numbers that do not match the patterns are ignored.\n",
        "* The example also shows that the code will extract emails with subdomains, and the + symbol in the username.\n",
        "* The international phone number is not extracted, because the regular expression is only set to extract US phone numbers.\n",
        "\n",
        "Business Use Cases:\n",
        "\n",
        "* Lead Generation: Scraping contact information from company websites, online directories, or social media.\n",
        "* Customer Relationship Management (CRM): Extracting customer contact details from email signatures or online forms.\n",
        "* Market Research: Gathering contact information for potential survey participants or focus group attendees.\n",
        "* Recruiting: Extracting contact details from resumes or LinkedIn profiles."
      ],
      "metadata": {
        "id": "tGNbcIYUhbQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_contact_details(html_content):\n",
        "    \"\"\"\n",
        "    Extracts contact details (emails, phone numbers) from HTML content.\n",
        "    \"\"\"\n",
        "    email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
        "    phone_pattern = r\"\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\"  # Basic US format\n",
        "    emails = re.findall(email_pattern, html_content)\n",
        "    phones = re.findall(phone_pattern, html_content)\n",
        "    return {\"emails\": emails, \"phones\": phones}"
      ],
      "metadata": {
        "id": "AMcgGQnNfr0j"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed Example:\n",
        "\n",
        "html_text = \"\"\"\n",
        "<p>Contact us:</p>\n",
        "<p>Email: info@example.com or support@company.net</p>\n",
        "<p>Phone: 123-456-7890, (555) 123-4567, or 987.654.3210</p>\n",
        "<p>Alternative email: user.name+tag@subdomain.example.co.uk</p>\n",
        "<p>Invalid email: invalid.email</p>\n",
        "<p>Invalid phone: 1234567</p>\n",
        "<p>International phone: +1-555-123-4567</p>\n",
        "\"\"\"\n",
        "\n",
        "contact_details = extract_contact_details(html_text)\n",
        "print(\"Extracted Contact Details:\", contact_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqOC7BBThkB1",
        "outputId": "9d3cfe1f-efe7-4559-9018-8f704704255d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Contact Details: {'emails': ['info@example.com', 'support@company.net', 'user.name+tag@subdomain.example.co.uk'], 'phones': ['123-456-7890', '(555) 123-4567', '987.654.3210', '555-123-4567']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C. Extract article content\n",
        "\n",
        "The function extracts the main article content by finding and concatenating the text from all paragraph tags, effectively removing other HTML elements.\n",
        "\n",
        "Business Use Cases:\n",
        "\n",
        "* Content Aggregation: Gathering articles from news websites, blogs, or industry publications for content marketing or research.\n",
        "* Sentiment Analysis: Extracting text content for analyzing customer reviews, social media posts, or news articles.\n",
        "* Knowledge Management: Building a database of articles or documents for internal search or analysis.\n",
        "* SEO Monitoring: Extracting article content to analyze keyword density and content quality for SEO purposes."
      ],
      "metadata": {
        "id": "zEhsVIB6iV2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_article_content(html_content):\n",
        "    \"\"\"Extracts article content from HTML (basic example).\"\"\"\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "    article_text = \"\"\n",
        "    for paragraph in soup.find_all(\"p\"):  # Assumes article content is in <p> tags\n",
        "        article_text += paragraph.get_text() + \" \"\n",
        "    return article_text.strip()"
      ],
      "metadata": {
        "id": "1rIpZuEOhrRX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed Example:\n",
        "html_text = \"\"\"\n",
        "<html>\n",
        "<head>\n",
        "    <title>My Article</title>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"article\">\n",
        "        <h1>Article Title</h1>\n",
        "        <p>This is the first paragraph of the article. It contains some text.</p>\n",
        "        <p>Here is the second paragraph. It has more details and information.</p>\n",
        "        <p>This paragraph contains a <strong>strong</strong> word.</p>\n",
        "        <div>\n",
        "            <p>This paragraph is nested inside a div.</p>\n",
        "        </div>\n",
        "        <p>And this is the final paragraph of the article.</p>\n",
        "        <p>\n",
        "            This paragraph has multiple lines.\n",
        "            It spans across several lines.\n",
        "        </p>\n",
        "    </div>\n",
        "    <div class=\"other-content\">\n",
        "        <p>This is some other content we don't need.</p>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "extracted_article = extract_article_content(html_text)\n",
        "print(\"Extracted Article Content:\", extracted_article)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv7kpcNMib_c",
        "outputId": "16bd9dcc-79a0-46e5-95bb-ae7c070d5f3b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Article Content: This is the first paragraph of the article. It contains some text. Here is the second paragraph. It has more details and information. This paragraph contains a strong word. This paragraph is nested inside a div. And this is the final paragraph of the article. \n",
            "            This paragraph has multiple lines.\n",
            "            It spans across several lines.\n",
            "         This is some other content we don't need.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D. Extract XML data\n",
        "\n",
        "Business Use Cases:\n",
        "\n",
        "* Data Integration: Extracting data from XML feeds or APIs for integration with internal systems.\n",
        "* Financial Reporting: Parsing XML-based financial reports (e.g., XBRL) for analysis.\n",
        "* E-commerce Data Exchange: Extracting product information from XML-based product catalogs.\n",
        "* Configuration Management: Parsing XML configuration files."
      ],
      "metadata": {
        "id": "mjzIpqcsj7Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_xml_data(xml_content, tag_name):\n",
        "    \"\"\"Extracts data from XML based on a tag name.\"\"\"\n",
        "    tag_pattern = rf\"<{tag_name}>(.*?)</{tag_name}>\"\n",
        "    matches = re.findall(tag_pattern, xml_content, re.DOTALL) #re.DOTALL to allow new line characters.\n",
        "    return matches"
      ],
      "metadata": {
        "id": "JneOyzlxigFv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed Example:\n",
        "xml_data = \"\"\"\n",
        "<data>\n",
        "    <product>\n",
        "        <name>Laptop</name>\n",
        "        <price>$1200</price>\n",
        "        <description>\n",
        "            A powerful laptop with high-performance components.\n",
        "            It is suitable for gaming and professional use.\n",
        "        </description>\n",
        "    </product>\n",
        "    <customer>\n",
        "        <email>customer@example.com</email>\n",
        "        <phone>555-123-4567</phone>\n",
        "    </customer>\n",
        "    <article>\n",
        "        <content>\n",
        "            This is a multi-line\n",
        "            article.\n",
        "            It contains several lines of text.\n",
        "        </content>\n",
        "    </article>\n",
        "</data>\n",
        "\"\"\"\n",
        "\n",
        "product_names = extract_xml_data(xml_data, \"name\")\n",
        "product_prices = extract_xml_data(xml_data, \"price\")\n",
        "product_descriptions = extract_xml_data(xml_data, \"description\")\n",
        "customer_emails = extract_xml_data(xml_data, \"email\")\n",
        "article_contents = extract_xml_data(xml_data, \"content\")\n",
        "\n",
        "print(\"Product Names:\", product_names)\n",
        "print(\"Product Prices:\", product_prices)\n",
        "print(\"Product Descriptions:\", product_descriptions)\n",
        "print(\"Customer Emails:\", customer_emails)\n",
        "print(\"Article Contents:\", article_contents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2KJh1nRkCwF",
        "outputId": "a5387971-5ba0-4944-ccc8-9843608a2ff0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Names: ['Laptop']\n",
            "Product Prices: ['$1200']\n",
            "Product Descriptions: ['\\n            A powerful laptop with high-performance components.\\n            It is suitable for gaming and professional use.\\n        ']\n",
            "Customer Emails: ['customer@example.com']\n",
            "Article Contents: ['\\n            This is a multi-line\\n            article.\\n            It contains several lines of text.\\n        ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E. Extract log info\n",
        "\n",
        "Example Breakdown:\n",
        "\n",
        "* The log_data list contains sample log lines with different formats and content.\n",
        "* The loop iterates through each log_line in log_data.\n",
        "* For each line, extract_log_info() is called.\n",
        "* If the line matches the pattern, the extracted information is printed as a dictionary.\n",
        "* If the line doesn't match the pattern (e.g., \"Invalid log line...\"), a message indicating the parsing failure is printed.\n",
        "* The example shows how the regex correctly extracts the timestamp, level and message from the different log lines.\n",
        "* The example also shows how the code deals with invalid log lines.\n",
        "* The example shows how the regex captures the message even if it contains colons, dots, or other symbols.\n",
        "\n",
        "Business Use Cases:\n",
        "\n",
        "* System Monitoring: Extracting timestamps, error messages, and performance metrics from server logs.\n",
        "* Security Auditing: Analyzing security logs for suspicious activity or unauthorized access.\n",
        "* Application Debugging: Extracting error messages and stack traces for troubleshooting software issues.\n",
        "* Business Intelligence: Analyzing log data for user behavior patterns or system performance trends."
      ],
      "metadata": {
        "id": "jJql2c8mTBZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_log_info(log_line):\n",
        "    \"\"\"\n",
        "    Extracts timestamp, log level, and message from a log line.\n",
        "    \"\"\"\n",
        "    log_pattern = r\"^(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) \\[(?P<level>\\w+)\\] (?P<message>.*)$\"\n",
        "    match = re.match(log_pattern, log_line)\n",
        "    if match:\n",
        "        return match.groupdict()\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "RnzT7084kI-R"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed Example:\n",
        "log_data = [\n",
        "    \"2023-10-27 10:00:00 [INFO] Application started successfully.\",\n",
        "    \"2023-10-27 10:05:15 [WARNING] Network connection timed out.\",\n",
        "    \"2023-10-27 10:10:30 [ERROR] Database query failed: SELECT * FROM users;\",\n",
        "    \"2023-10-27 10:15:45 [DEBUG] User 'john.doe' logged in from IP 192.168.1.100.\",\n",
        "    \"2023-10-27 10:20:00 [CRITICAL] System encountered an unexpected error and will shut down.\",\n",
        "    \"2023-10-27 10:25:15 [INFO] Data processing completed in 5 seconds.\",\n",
        "    \"2023-10-27 10:30:30 [DEBUG] Received request: GET /api/data?id=123\",\n",
        "    \"Invalid log line - missing timestamp\",\n",
        "    \"2023-10-27 10:35:00 [INFO] Log line with no message\"\n",
        "]"
      ],
      "metadata": {
        "id": "AcDyeBOATQZS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage:\n",
        "for log_line in log_data:\n",
        "    log_info = extract_log_info(log_line)\n",
        "    if log_info:\n",
        "        print(\"Extracted Log Info:\", log_info)\n",
        "    else:\n",
        "        print(f\"Failed to parse log line: '{log_line}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh1aZV-PTUAB",
        "outputId": "1cb1962e-30a6-49bc-fbe4-ee986c3405a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Log Info: {'timestamp': '2023-10-27 10:00:00', 'level': 'INFO', 'message': 'Application started successfully.'}\n",
            "Extracted Log Info: {'timestamp': '2023-10-27 10:05:15', 'level': 'WARNING', 'message': 'Network connection timed out.'}\n",
            "Extracted Log Info: {'timestamp': '2023-10-27 10:10:30', 'level': 'ERROR', 'message': 'Database query failed: SELECT * FROM users;'}\n",
            "Extracted Log Info: {'timestamp': '2023-10-27 10:15:45', 'level': 'DEBUG', 'message': \"User 'john.doe' logged in from IP 192.168.1.100.\"}\n",
            "Extracted Log Info: {'timestamp': '2023-10-27 10:20:00', 'level': 'CRITICAL', 'message': 'System encountered an unexpected error and will shut down.'}\n",
            "Extracted Log Info: {'timestamp': '2023-10-27 10:25:15', 'level': 'INFO', 'message': 'Data processing completed in 5 seconds.'}\n",
            "Extracted Log Info: {'timestamp': '2023-10-27 10:30:30', 'level': 'DEBUG', 'message': 'Received request: GET /api/data?id=123'}\n",
            "Failed to parse log line: 'Invalid log line - missing timestamp'\n",
            "Extracted Log Info: {'timestamp': '2023-10-27 10:35:00', 'level': 'INFO', 'message': 'Log line with no message'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F. Find Log error pattern\n",
        "\n",
        "Example Breakdown:\n",
        "\n",
        "Log Data:\n",
        "\n",
        "The log_data list contains sample log lines with different log levels and messages.\n",
        "\n",
        "Finding Error Logs:\n",
        "\n",
        "* The find_error_patterns() function is called with log_data.\n",
        "* The regex r\"ERROR|CRITICAL|FAILURE\" is used to find lines containing error-related keywords.\n",
        "* The re.IGNORECASE flag ensures that the search is case-insensitive.\n",
        "* The list comprehension filters the log_data list, keeping only the lines that match the error pattern.\n",
        "\n",
        "Output:\n",
        "\n",
        "The error_logs list will contain the following lines:\n",
        "\n",
        "* \"2023-10-27 10:10:30 [ERROR] Database query failed: SELECT * FROM users;\"\n",
        "* \"2023-10-27 10:20:00 [CRITICAL] System encountered an unexpected error and will shut down.\"\n",
        "* \"2023-10-27 10:40:00 [Failure] Job failed due to memory error\"\n",
        "* \"2023-10-27 10:45:00 [info] This line has an error, but in lowercase\"\n",
        "\n",
        "In essence, the function efficiently extracts all log lines that are likely related to errors, simplifying the process of error analysis from large log files.\n",
        "\n",
        "Business Use Cases:\n",
        "\n",
        "* Proactive System Maintenance: Quickly identifying and addressing critical errors in server logs.\n",
        "* Incident Response: Filtering log data to isolate error messages during a system outage or security incident.\n",
        "* Root Cause Analysis: Analyzing error logs to determine the underlying cause of system failures."
      ],
      "metadata": {
        "id": "p8TTkDjZV07I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def find_error_patterns(log_data):\n",
        "    \"\"\"\n",
        "    Finds log entries matching error patterns.\n",
        "    \"\"\"\n",
        "    error_pattern = r\"ERROR|CRITICAL|FAILURE\"\n",
        "    errors = [line for line in log_data if re.search(error_pattern, line, re.IGNORECASE)]\n",
        "    return errors"
      ],
      "metadata": {
        "id": "CTvIRIBRTXqe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed Example:\n",
        "log_data = [\n",
        "    \"2023-10-27 10:00:00 [INFO] Application started successfully.\",\n",
        "    \"2023-10-27 10:05:15 [WARNING] Connection timeout.\",\n",
        "    \"2023-10-27 10:10:30 [ERROR] Database query failed: SELECT * FROM users;\",\n",
        "    \"2023-10-27 10:15:45 [INFO] User login successful.\",\n",
        "    \"2023-10-27 10:20:00 [CRITICAL] System encountered an unexpected error and will shut down.\",\n",
        "    \"2023-10-27 10:25:15 [INFO] Data processing completed in 5 seconds.\",\n",
        "    \"2023-10-27 10:30:30 [DEBUG] Unusual activity detected: user login from unknown IP.\",\n",
        "    \"2023-10-27 10:35:00 [INFO] Log line with no message\",\n",
        "    \"2023-10-27 10:40:00 [Failure] Job failed due to memory error\",\n",
        "    \"2023-10-27 10:45:00 [info] This line has an error, but in lowercase\"\n",
        "]\n",
        "\n",
        "# Example Usage:\n",
        "error_logs = find_error_patterns(log_data)\n",
        "print(\"Error Logs:\", error_logs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHBYcN27V7zC",
        "outputId": "d224711c-43f8-4160-c24e-c771c08561d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Logs: ['2023-10-27 10:10:30 [ERROR] Database query failed: SELECT * FROM users;', '2023-10-27 10:20:00 [CRITICAL] System encountered an unexpected error and will shut down.', '2023-10-27 10:40:00 [Failure] Job failed due to memory error', '2023-10-27 10:45:00 [info] This line has an error, but in lowercase']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## G. Find Anomalies\n",
        "\n",
        "Example Breakdown:\n",
        "\n",
        "Log Data:\n",
        "\n",
        "* The log_data list contains sample log lines with various log levels and messages.\n",
        "\n",
        "Example Usage 1: Finding \"timeout\" Logs:\n",
        "\n",
        "* anomaly_pattern1 = r\"timeout\": The regex searches for the literal word \"timeout\" (case-insensitive).\n",
        "* The timeout_logs list will contain:\n",
        "\n",
        "\"2023-10-27 10:05:15 [WARNING] Connection timeout.\"\n",
        "\n",
        "Example Usage 2: Finding \"CPU\" or \"Disk\" Logs:\n",
        "\n",
        "* anomaly_pattern2 = r\"CPU|Disk\": The regex uses the \"or\" operator (|) to find lines containing either \"CPU\" or \"Disk\".\n",
        "\n",
        "The resource_logs list will contain:\n",
        "\n",
        "* \"2023-10-27 10:35:00 [INFO] High CPU usage detected.\"\n",
        "* \"2023-10-27 10:50:00 [warning] Disk space nearing capacity.\"\n",
        "\n",
        "Example Usage 3: Finding IP Address Logs:\n",
        "\n",
        "* anomaly_pattern3 = r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\": The regex searches for the IP address format (e.g., 192.168.1.100).\n",
        "* The ip_logs list will contain:\n",
        "\n",
        "\"2023-10-27 10:30:30 [DEBUG] Unusual activity detected: user login from unknown IP.\"\n",
        "\n",
        "Example Usage 4: Finding \"failed\" Logs:\n",
        "\n",
        "* anomaly_pattern4 = r\"failed\": The regex searches for the literal word \"failed\" (case-insensitive).\n",
        "* The failed_logs list will contain:\n",
        "\n",
        "\"2023-10-27 10:10:30 [ERROR] Database query failed: SELECT * FROM users;\"\n",
        "\n",
        "\"2023-10-27 10:40:00 [Failure] Job failed due to memory error.\"\n",
        "\n",
        "In essence, the function allows you to define custom regex patterns to find any anomalies or specific events within your log data, providing a powerful way to filter and analyze log files.\n",
        "\n",
        "Business Use Cases:\n",
        "\n",
        "* Fraud Detection: Identifying unusual patterns in transaction logs or user activity logs.\n",
        "* Network Security: Detecting suspicious network traffic patterns in firewall logs.\n",
        "* Predictive Maintenance: Identifying anomalies in sensor data or machine logs that may indicate impending equipment failures.\n",
        "* Business Process Monitoring: Discovering deviations from normal business process flows in application logs."
      ],
      "metadata": {
        "id": "nBEAMlrhX8CM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def find_anomalies(log_data, anomaly_pattern):\n",
        "    \"\"\"\n",
        "    Finds log entries matching a given anomaly pattern.\n",
        "    \"\"\"\n",
        "    anomalies = [line for line in log_data if re.search(anomaly_pattern, line, re.IGNORECASE)]\n",
        "    return anomalies"
      ],
      "metadata": {
        "id": "tF2JgV30WAPR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed Example:\n",
        "\n",
        "log_data = [\n",
        "    \"2023-10-27 10:00:00 [INFO] Application started successfully.\",\n",
        "    \"2023-10-27 10:05:15 [WARNING] Connection timeout.\",\n",
        "    \"2023-10-27 10:10:30 [ERROR] Database query failed: SELECT * FROM users;\",\n",
        "    \"2023-10-27 10:15:45 [INFO] User login successful.\",\n",
        "    \"2023-10-27 10:20:00 [CRITICAL] System encountered an unexpected error and will shut down.\",\n",
        "    \"2023-10-27 10:25:15 [INFO] Data processing completed in 5 seconds.\",\n",
        "    \"2023-10-27 10:30:30 [DEBUG] Unusual activity detected: user login from unknown IP.\",\n",
        "    \"2023-10-27 10:35:00 [INFO] High CPU usage detected.\",\n",
        "    \"2023-10-27 10:40:00 [Failure] Job failed due to memory error.\",\n",
        "    \"2023-10-27 10:45:00 [info] This line has an error, but in lowercase.\",\n",
        "    \"2023-10-27 10:50:00 [warning] Disk space nearing capacity.\"\n",
        "]"
      ],
      "metadata": {
        "id": "P0W__tZBX_6V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage 1: Finding lines with \"timeout\"\n",
        "\n",
        "anomaly_pattern1 = r\"timeout\"\n",
        "timeout_logs = find_anomalies(log_data, anomaly_pattern1)\n",
        "print(\"Timeout Logs:\", timeout_logs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk4k5_KZYEiz",
        "outputId": "770979d1-2433-4e2a-fcf9-73271fab7b91"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timeout Logs: ['2023-10-27 10:05:15 [WARNING] Connection timeout.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage 2: Finding lines with \"CPU\" or \"Disk\"\n",
        "\n",
        "anomaly_pattern2 = r\"CPU|Disk\"\n",
        "resource_logs = find_anomalies(log_data, anomaly_pattern2)\n",
        "print(\"\\nResource Logs:\", resource_logs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L12_z5EHYIp7",
        "outputId": "cef9e32c-bdbb-4b38-d4c5-e606e82e0ae0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resource Logs: ['2023-10-27 10:35:00 [INFO] High CPU usage detected.', '2023-10-27 10:50:00 [warning] Disk space nearing capacity.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage 3: Finding lines with an IP address (potential security anomaly)\n",
        "\n",
        "anomaly_pattern3 = r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\"\n",
        "ip_logs = find_anomalies(log_data, anomaly_pattern3)\n",
        "print(\"\\nIP Address Logs:\", ip_logs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cVSKbarYUMR",
        "outputId": "972b812a-dc1b-4bbe-8769-50b68ab670c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "IP Address Logs: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage 4: Finding lines with \"failed\"\n",
        "\n",
        "anomaly_pattern4 = r\"failed\"\n",
        "failed_logs = find_anomalies(log_data, anomaly_pattern4)\n",
        "print(\"\\nFailed Logs:\", failed_logs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPFUe1OEYZsZ",
        "outputId": "2870373d-2dce-482e-e787-a8e6d588ab0b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Failed Logs: ['2023-10-27 10:10:30 [ERROR] Database query failed: SELECT * FROM users;', '2023-10-27 10:40:00 [Failure] Job failed due to memory error.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## H. Extract data from csv\n",
        "\n",
        "Example Breakdown:\n",
        "\n",
        "CSV Data:\n",
        "\n",
        "The csv_data string contains sample CSV data with columns for \"Name,\" \"Age,\" \"City,\" and \"Occupation.\"\n",
        "It also contains rows with missing values to demonstrate how the code handles them.\n",
        "Extracting Names:\n",
        "\n",
        "* names = extract_data_from_csv(csv_data, 0): Extracts the values from the first column (index 0), which are the names.\n",
        "* names will be ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank'].\n",
        "\n",
        "Extracting Ages:\n",
        "\n",
        "* ages = extract_data_from_csv(csv_data, 1): Extracts the values from the second column (index 1), which are the ages.\n",
        "* ages will be ['30', '25', '35', '40', '', '22'].\n",
        "* Note that 'Eva' has an empty string for age.\n",
        "\n",
        "Extracting Cities:\n",
        "\n",
        "* cities = extract_data_from_csv(csv_data, 2): Extracts the values from the third column (index 2), which are the cities.\n",
        "* cities will be ['New York', 'London', 'Paris', 'Tokyo', 'Berlin', ''].\n",
        "* Note that 'Frank' has an empty string for city.\n",
        "\n",
        "Extracting Occupations:\n",
        "\n",
        "* occupations = extract_data_from_csv(csv_data, 3): Extracts the values from the fourth column (index 3), which are the occupations.\n",
        "* occupations will be ['Engineer', 'Teacher', 'Artist', 'Manager', 'Developer', 'Student'].\n",
        "\n",
        "Example with Invalid Column Index:\n",
        "\n",
        "* invalid_column = extract_data_from_csv(csv_data, 4): This will raise an IndexError, because the CSV data only has columns with indexes 0 to 3. It serves to show that if an invalid column index is provided, the code will raise the appropriate error.\n",
        "* It is good practice to add try and except blocks to your code to handle these kinds of errors.\n",
        "\n",
        "In essence, the function provides a simple way to extract data from a specific column in a CSV string, handling basic CSV parsing and skipping empty rows.\n",
        "\n",
        "Business Use Cases:\n",
        "\n",
        "* Data Migration: Extracting data from CSV files for importing into databases or other systems.\n",
        "* Data Analysis: Parsing CSV data for creating reports, charts, or visualizations.\n",
        "* Financial Reporting: Extracting financial data from CSV-based transaction logs.\n",
        "* Customer Data Management: Importing customer data from CSV files into CRM systems."
      ],
      "metadata": {
        "id": "siVbdpxuaYYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import csv\n",
        "\n",
        "def extract_data_from_csv(csv_content, column_index):\n",
        "    \"\"\"Extracts data from a specific column in a CSV string.\"\"\"\n",
        "    reader = csv.reader(csv_content.splitlines())\n",
        "    data = []\n",
        "    for row in reader:\n",
        "        if row:  # Skip empty rows\n",
        "            try:\n",
        "                data.append(row[column_index])\n",
        "            except IndexError:\n",
        "                # Handle the error, e.g., print a message or append a default value\n",
        "                print(f\"Column index {column_index} out of bounds for row: {row}\")\n",
        "                data.append('')  # Append an empty string as a default\n",
        "    return data"
      ],
      "metadata": {
        "id": "AIb-636UYj0q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed Example:\n",
        "\n",
        "csv_data = \"\"\"\n",
        "Name,Age,City,Occupation\n",
        "Alice,30,New York,Engineer\n",
        "Bob,25,London,Teacher\n",
        "Charlie,35,Paris,Artist\n",
        "David,40,Tokyo,Manager\n",
        "Eva,,Berlin,Developer\n",
        "Frank,22,,Student\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HbdOSS5McFsn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract names (column 0)\n",
        "names = extract_data_from_csv(csv_data, 0)\n",
        "print(\"Names:\", names)\n",
        "\n",
        "# Extract ages (column 1)\n",
        "ages = extract_data_from_csv(csv_data, 1)\n",
        "print(\"Ages:\", ages)\n",
        "\n",
        "# Extract cities (column 2)\n",
        "cities = extract_data_from_csv(csv_data, 2)\n",
        "print(\"Cities:\", cities)\n",
        "\n",
        "# Extract occupations (column 3)\n",
        "occupations = extract_data_from_csv(csv_data, 3)\n",
        "print(\"Occupations:\", occupations)\n",
        "\n",
        "# Example with an out-of-bounds column index:\n",
        "invalid_column = extract_data_from_csv(csv_data, 4) # This will raise an IndexError\n",
        "print(\"Invalid column\", invalid_column)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMDFdrDRcKAb",
        "outputId": "583ca849-6506-442e-cd8e-4356861f97ab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Names: ['Name', 'Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank']\n",
            "Ages: ['Age', '30', '25', '35', '40', '', '22']\n",
            "Cities: ['City', 'New York', 'London', 'Paris', 'Tokyo', 'Berlin', '']\n",
            "Occupations: ['Occupation', 'Engineer', 'Teacher', 'Artist', 'Manager', 'Developer', 'Student']\n",
            "Column index 4 out of bounds for row: ['Name', 'Age', 'City', 'Occupation']\n",
            "Column index 4 out of bounds for row: ['Alice', '30', 'New York', 'Engineer']\n",
            "Column index 4 out of bounds for row: ['Bob', '25', 'London', 'Teacher']\n",
            "Column index 4 out of bounds for row: ['Charlie', '35', 'Paris', 'Artist']\n",
            "Column index 4 out of bounds for row: ['David', '40', 'Tokyo', 'Manager']\n",
            "Column index 4 out of bounds for row: ['Eva', '', 'Berlin', 'Developer']\n",
            "Column index 4 out of bounds for row: ['Frank', '22', '', 'Student']\n",
            "Invalid column ['', '', '', '', '', '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I. Parse Config file\n",
        "\n",
        "Configuration Data:\n",
        "\n",
        "* The config_file_data string contains sample configuration data with comments, different spacing, and various value formats.\n",
        "\n",
        "Key and Value Patterns:\n",
        "\n",
        "* key_pattern = r\"(\\w+)\": Matches one or more word characters (alphanumeric and underscore).\n",
        "* value_pattern = r\"(.+)\": Matches one or more of any character. This is very general.\n",
        "\n",
        "Parsing Configuration:\n",
        "\n",
        "* The parse_config_file() function is called with the configuration data and the key/value patterns.\n",
        "* The regex pattern finds key-value pairs in each line, ignoring comments and empty lines.\n",
        "\n",
        "Example with more restrictive value pattern\n",
        "\n",
        "* The example shows how to use a different value pattern to parse only certain kinds of values.\n",
        "\n",
        "Example with only numbers as values\n",
        "\n",
        "* The example shows how to parse only keys with numeric values.\n",
        "\n",
        "Business Use Cases:\n",
        "\n",
        "* Software Deployment: Parsing configuration files for setting application parameters or environment variables.\n",
        "* System Administration: Parsing configuration files for managing server settings or network configurations.\n",
        "* Data Integration: Parsing configuration files for defining data source connections or transformation rules.\n",
        "* Automation: Parsing configuration files to automate system tasks or workflows."
      ],
      "metadata": {
        "id": "Djuf5HZzd7na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def parse_config_file(config_content, key_pattern, value_pattern):\n",
        "    \"\"\"Parses key-value pairs from a configuration file string.\"\"\"\n",
        "    config_data = {}\n",
        "    lines = config_content.splitlines()\n",
        "    for line in lines:\n",
        "        line = line.strip()  # Remove leading/trailing whitespace\n",
        "        if line and not line.startswith(\"#\"):  # Skip empty lines and comments\n",
        "            match = re.search(rf\"{key_pattern}\\s*=\\s*{value_pattern}\", line)\n",
        "            if match:\n",
        "                key = match.group(1).strip()\n",
        "                value = match.group(2).strip()\n",
        "                config_data[key] = value\n",
        "    return config_data"
      ],
      "metadata": {
        "id": "uHzrNvzzeHhI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detailed Example:\n",
        "config_file_data = \"\"\"\n",
        "# This is a sample configuration file\n",
        "\n",
        "# Database settings\n",
        "DATABASE_HOST = localhost\n",
        "DATABASE_PORT = 5432\n",
        "DATABASE_USER = myuser\n",
        "DATABASE_PASSWORD = mypassword\n",
        "\n",
        "# Application settings\n",
        "APP_NAME = MyApp\n",
        "APP_VERSION = 1.2.3\n",
        "LOG_LEVEL = INFO\n",
        "\n",
        "# Server settings\n",
        "SERVER_IP = 192.168.1.100\n",
        "SERVER_PORT = 8080\n",
        "\n",
        "# More settings with different spacing\n",
        "API_KEY    =    ABCDEFG12345\n",
        "TIMEOUT = 60 #seconds\n",
        "\n",
        "#Example with spaces in values\n",
        "FILE_PATH = /path/to/my files\n",
        "\n",
        "#Example with quotes around the value\n",
        "MESSAGE = \"Hello, World!\"\n",
        "\n",
        "#Example of multiline value.\n",
        "MULTI_LINE = This is a\n",
        "multiline value.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "K067b8opgMk_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage:\n",
        "key_pattern = r\"(\\w+)\"  # Matches one or more word characters (alphanumeric and underscore)\n",
        "value_pattern = r\"(.+)\" # Matches one or more of any character\n",
        "\n",
        "config = parse_config_file(config_file_data, key_pattern, value_pattern)\n",
        "print(\"Parsed Configuration:\", config)\n",
        "\n",
        "# Example Usage with more restrictive value pattern\n",
        "key_pattern2 = r\"(\\w+)\"\n",
        "value_pattern2 = r\"([\\w./]+)\" #matches words, dots and slashes\n",
        "\n",
        "config2 = parse_config_file(config_file_data, key_pattern2, value_pattern2)\n",
        "print(\"\\nParsed Configuration 2:\", config2)\n",
        "\n",
        "#Example usage with only numbers as values.\n",
        "key_pattern3 = r\"(\\w+)\"\n",
        "value_pattern3 = r\"(\\d+)\" #matches only digits.\n",
        "config3 = parse_config_file(config_file_data, key_pattern3, value_pattern3)\n",
        "print(\"\\nParsed Configuration 3:\", config3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGmGu5CWgRle",
        "outputId": "d803ee10-cfa2-46ab-944e-5177ed18e595"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed Configuration: {'DATABASE_HOST': 'localhost', 'DATABASE_PORT': '5432', 'DATABASE_USER': 'myuser', 'DATABASE_PASSWORD': 'mypassword', 'APP_NAME': 'MyApp', 'APP_VERSION': '1.2.3', 'LOG_LEVEL': 'INFO', 'SERVER_IP': '192.168.1.100', 'SERVER_PORT': '8080', 'API_KEY': 'ABCDEFG12345', 'TIMEOUT': '60 #seconds', 'FILE_PATH': '/path/to/my files', 'MESSAGE': '\"Hello, World!\"', 'MULTI_LINE': 'This is a'}\n",
            "\n",
            "Parsed Configuration 2: {'DATABASE_HOST': 'localhost', 'DATABASE_PORT': '5432', 'DATABASE_USER': 'myuser', 'DATABASE_PASSWORD': 'mypassword', 'APP_NAME': 'MyApp', 'APP_VERSION': '1.2.3', 'LOG_LEVEL': 'INFO', 'SERVER_IP': '192.168.1.100', 'SERVER_PORT': '8080', 'API_KEY': 'ABCDEFG12345', 'TIMEOUT': '60', 'FILE_PATH': '/path/to/my', 'MULTI_LINE': 'This'}\n",
            "\n",
            "Parsed Configuration 3: {'DATABASE_PORT': '5432', 'APP_VERSION': '1', 'SERVER_IP': '192', 'SERVER_PORT': '8080', 'TIMEOUT': '60'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xDhgN12DhHPT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}